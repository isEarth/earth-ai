"""
causal_cls_trainer.py

ëª©ì :
    í•œêµ­ì–´ ì¸ê³¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ì„ Hugging Face Transformersì™€ Trainer APIë¥¼ ì´ìš©í•´ í•™ìŠµí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - ìµœì‹  CSV ë°ì´í„° ìë™ ë¡œë“œ ë° í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
    - KF-DeBERTa ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ
    - í‰ê°€ ì§€í‘œ(metrics) ê³„ì‚°: Accuracy, Precision, Recall, F1, ROC AUC
    - ê²°ê³¼ ì‹œê°í™”:
        - í•™ìŠµ ë° í‰ê°€ ì†ì‹¤ ê·¸ë˜í”„
        - í˜¼ë™ í–‰ë ¬
        - ROC ê³¡ì„ 
    - ìµœê³ ì˜ ëª¨ë¸ ìë™ ì €ì¥ (EarlyStopping í¬í•¨)

êµ¬ì„± ìš”ì†Œ:
    - `load_and_split_csv`: ìµœì‹  CSVë¥¼ ë¶ˆëŸ¬ì™€ í•™ìŠµ/ê²€ì¦ì…‹ ìƒì„±
    - `tokenize_fn`: ë¬¸ì¥ì„ tokenizerë¡œ ë³€í™˜
    - `compute_metrics`: ì»¤ìŠ¤í…€ í‰ê°€ ì§€í‘œ ê³„ì‚°
    - `plot_metrics`: í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    - `plot_confusion`: í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
    - `plot_roc_auc`: ROC ì»¤ë¸Œ ì‹œê°í™”

ì‚¬ìš©ë²•:
    - `python causal_cls_trainer.py`
    - ê¸°ë³¸ì ìœ¼ë¡œ `./data/` ë””ë ‰í† ë¦¬ ë‚´ ìµœì‹  CSVë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì¶œë ¥ ë””ë ‰í† ë¦¬:
    - í•™ìŠµ ê²°ê³¼ëŠ” `./runs/run_YYYYMMDD_HHMMSS/` ì— ì €ì¥ë˜ë©° ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•©ë‹ˆë‹¤:
        - `best_model/`: ìµœì  ëª¨ë¸ ê°€ì¤‘ì¹˜
        - `training_loss.png`, `eval_f1.png`, `confusion_matrix.png`, `roc_curve.png` ë“± ì‹œê°í™” ê²°ê³¼

"""

import os
import glob
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datasets import Dataset
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback
)
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve
import torch

from tqdm import tqdm
from datetime import datetime

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(42)

# plt í•œê¸€ì²˜ë¦¬
plt.rcParams['font.family'] ='NanumGothic'
plt.rcParams['axes.unicode_minus'] =False

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) í† í¬ë‚˜ì´ì €ì™€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ

MODEL_NAME = "kakaobank/kf-deberta-base"
MODEL_PATH = '/home/eunhyea/EARTH/causal/causal_cls/checkpoint-'

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)

model     = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=2  # 0: ë¹„ì¸ê³¼, 1: ì¸ê³¼
)

# model     = AutoModelForSequenceClassification.from_pretrained(
#     MODEL_PATH,
#     num_labels=2  # 0: ë¹„ì¸ê³¼, 1: ì¸ê³¼
# )

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
model.to(device)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def compute_metrics(pred):
    """
    Trainerê°€ ê²€ì¦í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë¡œ,
    logitsì™€ ì‹¤ì œ ë ˆì´ë¸”ì„ ë¹„êµí•´ accuracy, precision, recall, f1 ë¦¬í„´
    """
    logits, labels = pred.predictions, pred.label_ids
    preds = np.argmax(logits, axis=-1)
    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    auc = roc_auc_score(labels, logits[:, 1])
    return {"accuracy": acc, "precision": p, "recall": r, "f1": f1, "roc_auc": auc}

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def load_and_split_csv(directory, test_size=0.2, seed=42):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ ìˆ˜ì •ëœ CSV íŒŒì¼ì„ ì½ì–´ì™€ HF Datasetìœ¼ë¡œ ë°˜í™˜
    """
    csv_files = glob.glob(os.path.join(directory, '*.csv'))
    if not csv_files:
        raise FileNotFoundError(f"âŒ '{directory}' ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ê°€ì¥ ë§ˆì§€ë§‰ ìˆ˜ì •ëœ íŒŒì¼ ì°¾ê¸°
    latest_csv = max(csv_files, key=os.path.getmtime)
    print(f"âœ… CSV íŒŒì¼ ë¡œë“œ: {latest_csv}")

    df = pd.read_csv(latest_csv)
    ds = Dataset.from_pandas(df)
    split = ds.train_test_split(test_size=test_size, seed=seed)

    train_ds = split["train"]
    val_ds = split["test"]

    return train_ds, val_ds


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def tokenize_fn(batch):
    """
    Hugging Face Dataset.map()ì— ë„˜ê¸°ëŠ” í† í¬ë‚˜ì´ì € í•¨ìˆ˜.
    batch["sentence"] ë¦¬ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— í† í¬ë‚˜ì´ì¦ˆí•´ì„œ
    'input_ids', 'attention_mask' ë“±ì„ ë°˜í™˜
    """
    return tokenizer(
        batch["sentence"],
        padding="max_length",
        truncation=True,
        max_length=128
    )


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_metrics(metrics, save_dir):
    for metric in ["loss", "eval_loss", "eval_accuracy", "eval_precision", "eval_recall", "eval_f1", "eval_roc_auc"]:
        if metric in metrics:
            plt.figure()
            plt.plot(metrics[metric], label=metric)
            plt.xlabel('Epoch')
            plt.ylabel(metric)
            plt.title(f'{metric} over epochs')
            plt.legend()
            plt.savefig(os.path.join(save_dir, f'{metric}.png'))
            plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_confusion(predictions, labels, save_dir):
    cm = confusion_matrix(labels, predictions)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ë¹„ì¸ê³¼', 'ì¸ê³¼'])
    fig, ax = plt.subplots(figsize=(6, 6))
    disp.plot(ax=ax, cmap='Blues', colorbar=False, values_format='d')
    plt.title('Confusion Matrix')
    plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'))
    plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_roc_auc(labels, probs, save_dir):
    fpr, tpr, _ = roc_curve(labels, probs)
    auc_score = roc_auc_score(labels, probs)
    plt.figure()
    plt.plot(fpr, tpr, label=f'ROC curve (area = {auc_score:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.savefig(os.path.join(save_dir, 'roc_curve.png'))
    plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def main():

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = f"./runs/run_{timestamp}"
    os.makedirs(save_dir, exist_ok=True)

    # 1) train.csv -> train, val split
    print("ğŸ“‚ train.csv ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    train_ds, val_ds = load_and_split_csv("./data", test_size=0.2, seed=42)

    # 2) í† í¬ë‚˜ì´ì¦ˆ: datasets.map() ì— desc ì¸ìë¥¼ ì£¼ë©´ tqdm ë°”ê°€ ìë™ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.
    print("ğŸ” train ë°ì´í„° í† í¬ë‚˜ì´ì¦ˆ ì¤‘...")
    train_ds = train_ds.map(
        tokenize_fn,
        batched=True,
        desc="Tokenizing train set"  # tqdm ë°” ì„¤ëª…
    )

    print("ğŸ” val ë°ì´í„° í† í¬ë‚˜ì´ì¦ˆ ì¤‘...")
    val_ds   = val_ds.map(
        tokenize_fn,
        batched=True,
        desc="Tokenizing val set"    # tqdm ë°” ì„¤ëª…
    )

    # 3) Trainer í˜¸í™˜ì„ ìœ„í•´ ì»¬ëŸ¼ëª… ë³€ê²½
    print("âœï¸ ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ ì¤‘ (label â†’ labels)...")
    train_ds = train_ds.rename_column("label", "labels")
    val_ds   = val_ds.rename_column("label", "labels")

    # 4) ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼(ì˜ˆ: pandas ì¸ë±ìŠ¤) ì œê±°
    #    Dataset.from_pandas() ì‹¤í–‰ ì‹œ "__index_level_0__" ì»¬ëŸ¼ì´ ë‚¨ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    if "__index_level_0__" in train_ds.column_names:
        train_ds = train_ds.remove_columns(["__index_level_0__"])
    if "__index_level_0__" in val_ds.column_names:
        val_ds   = val_ds.remove_columns(["__index_level_0__"])

    # 5) TrainingArguments & Trainer ì„¤ì •
    args = TrainingArguments(
        output_dir                   = save_dir,
        learning_rate                = 2e-5,
        per_device_train_batch_size  = 16,
        per_device_eval_batch_size   = 16,
        num_train_epochs             = 20,
        evaluation_strategy          = "epoch",
        save_strategy                = "epoch",
        load_best_model_at_end       = True,
        metric_for_best_model        = "f1",
        fp16                         = True,  # GPU í™˜ê²½ì´ ì•„ë‹ˆë©´ Falseë¡œ ë°”ê¿”ì£¼ì„¸ìš”
    )

    trainer = Trainer(
        model           = model,
        args            = args,
        train_dataset   = train_ds,
        eval_dataset    = val_ds,
        compute_metrics = compute_metrics,
        callbacks       = [EarlyStoppingCallback(early_stopping_patience=2)],
    )

    # 6) í•™ìŠµ ì‹œì‘
    print("ğŸš€ í•™ìŠµ ì‹œì‘...")
    trainer.train()

    # 7) í•™ìŠµ ì™„ë£Œ í›„, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    trainer.save_model(os.path.join(save_dir, "best_model"))
    print("âœ… í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥ë¨: ./causal_cls-best")

    # 8) í‰ê°€ì§€í‘œ ì €ì¥
    metrics = trainer.state.log_history
    metrics_dict = {}
    for entry in metrics:
        for key, value in entry.items():
            if key not in metrics_dict:
                metrics_dict[key] = []
            metrics_dict[key].append(value)
    plot_metrics(metrics_dict, save_dir)

    outputs = trainer.predict(val_ds)
    preds = np.argmax(outputs.predictions, axis=-1)
    probs = torch.nn.functional.softmax(torch.tensor(outputs.predictions), dim=-1)[:, 1].numpy()
    labels = outputs.label_ids

    plot_confusion(preds, labels, save_dir)
    plot_roc_auc(labels, probs, save_dir)
    print(f"âœ… ëª¨ë“  ê·¸ë˜í”„ì™€ ê²°ê³¼ê°€ {save_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()