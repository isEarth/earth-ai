"""
causal_train.py

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•œêµ­ì–´ ì¸ê³¼ê´€ê³„ ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ DeBERTa ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

- ì…ë ¥: CSV íŒŒì¼ (./data/*.csv) - sentence, label
- ì²˜ë¦¬: í† í°í™”, ë°ì´í„° ë¶„í• , ëª¨ë¸ í•™ìŠµ, í‰ê°€ì§€í‘œ ì‹œê°í™”
- ì¶œë ¥:
    - ./runs/run_YYYYMMDD_HHMMSS ë””ë ‰í† ë¦¬ ë‚´ë¶€ì— ëª¨ë¸ ë° ì‹œê°í™” ê²°ê³¼ ì €ì¥

í•™ìŠµ ëŒ€ìƒ:
    0: ë¹„ì¸ê³¼ ë¬¸ì¥
    1: ì¸ê³¼ ë¬¸ì¥

ì‚¬ìš© ëª¨ë¸:
    kakaobank/kf-deberta-base
"""

import os
import glob
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datasets import Dataset
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback
)
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve
import torch

from tqdm import tqdm
from datetime import datetime

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def set_seed(seed):
    """
    ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ ê³ ì • í•¨ìˆ˜

    Args:
        seed (int): ì‹œë“œ ê°’
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(42)

# plt í•œê¸€ì²˜ë¦¬
plt.rcParams['font.family'] ='NanumGothic'
plt.rcParams['axes.unicode_minus'] =False

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) í† í¬ë‚˜ì´ì €ì™€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ

MODEL_NAME = "kakaobank/kf-deberta-base"
MODEL_PATH = '/home/eunhyea/EARTH/causal/causal_cls/checkpoint-'

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)

model     = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=2  # 0: ë¹„ì¸ê³¼, 1: ì¸ê³¼
)

# model     = AutoModelForSequenceClassification.from_pretrained(
#     MODEL_PATH,
#     num_labels=2  # 0: ë¹„ì¸ê³¼, 1: ì¸ê³¼
# )

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
model.to(device)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def compute_metrics(pred):
    """
    Trainer ê²€ì¦ ë‹¨ê³„ì—ì„œ í‰ê°€ ì§€í‘œ ê³„ì‚°

    Args:
        pred (EvalPrediction): ì˜ˆì¸¡ ê²°ê³¼ ê°ì²´

    Returns:
        dict: accuracy, precision, recall, f1, roc_auc
    """
    logits, labels = pred.predictions, pred.label_ids
    preds = np.argmax(logits, axis=-1)
    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)
    auc = roc_auc_score(labels, logits[:, 1])
    return {"accuracy": acc, "precision": p, "recall": r, "f1": f1, "roc_auc": auc}

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def load_and_split_csv(directory, test_size=0.2, seed=42):
    """
    ê°€ì¥ ìµœì‹  CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  train/val ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„ë¦¬

    Args:
        directory (str): CSV íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        test_size (float): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        seed (int): ëœë¤ ì‹œë“œ

    Returns:
        tuple: (train_ds, val_ds) í˜•íƒœì˜ Hugging Face Dataset ê°ì²´
    """
    csv_files = glob.glob(os.path.join(directory, '*.csv'))
    if not csv_files:
        raise FileNotFoundError(f"âŒ '{directory}' ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ê°€ì¥ ë§ˆì§€ë§‰ ìˆ˜ì •ëœ íŒŒì¼ ì°¾ê¸°
    latest_csv = max(csv_files, key=os.path.getmtime)
    print(f"âœ… CSV íŒŒì¼ ë¡œë“œ: {latest_csv}")

    df = pd.read_csv(latest_csv)
    ds = Dataset.from_pandas(df)
    split = ds.train_test_split(test_size=test_size, seed=seed)

    train_ds = split["train"]
    val_ds = split["test"]

    return train_ds, val_ds


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def tokenize_fn(batch):
    """
    Dataset.map()ì— ë„˜ê¸°ëŠ” í† í¬ë‚˜ì´ì € í•¨ìˆ˜

    Args:
        batch (dict): {"sentence": List[str]}

    Returns:
        dict: tokenized inputs (input_ids, attention_mask)
    """
    return tokenizer(
        batch["sentence"],
        padding="max_length",
        truncation=True,
        max_length=128
    )


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_metrics(metrics, save_dir):
    """
    í•™ìŠµ ë¡œê·¸(metric) ì‹œê°í™”

    Args:
        metrics (dict): metric ë¡œê·¸ ë”•ì…”ë„ˆë¦¬
        save_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    for metric in ["loss", "eval_loss", "eval_accuracy", "eval_precision", "eval_recall", "eval_f1", "eval_roc_auc"]:
        if metric in metrics:
            plt.figure()
            plt.plot(metrics[metric], label=metric)
            plt.xlabel('Epoch')
            plt.ylabel(metric)
            plt.title(f'{metric} over epochs')
            plt.legend()
            plt.savefig(os.path.join(save_dir, f'{metric}.png'))
            plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_confusion(predictions, labels, save_dir):
    """
    í˜¼ë™í–‰ë ¬ ì‹œê°í™” ë° ì €ì¥

    Args:
        predictions (List[int]): ì˜ˆì¸¡ ë ˆì´ë¸”
        labels (List[int]): ì‹¤ì œ ë ˆì´ë¸”
        save_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬
    """
    cm = confusion_matrix(labels, predictions)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ë¹„ì¸ê³¼', 'ì¸ê³¼'])
    fig, ax = plt.subplots(figsize=(6, 6))
    disp.plot(ax=ax, cmap='Blues', colorbar=False, values_format='d')
    plt.title('Confusion Matrix')
    plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'))
    plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def plot_roc_auc(labels, probs, save_dir):
    """
    ROC ê³¡ì„  ì‹œê°í™” ë° ì €ì¥

    Args:
        labels (List[int]): ì‹¤ì œ ë ˆì´ë¸”
        probs (List[float]): ì–‘ì„± í´ë˜ìŠ¤ í™•ë¥ 
        save_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬
    """
    fpr, tpr, _ = roc_curve(labels, probs)
    auc_score = roc_auc_score(labels, probs)
    plt.figure()
    plt.plot(fpr, tpr, label=f'ROC curve (area = {auc_score:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.savefig(os.path.join(save_dir, 'roc_curve.png'))
    plt.close()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def main():
    """
    ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
        1. CSV ë¡œë“œ ë° ë°ì´í„°ì…‹ ë¶„ë¦¬
        2. í† í°í™”
        3. Trainer ì„¤ì • ë° í•™ìŠµ
        4. ëª¨ë¸ ì €ì¥ ë° ì‹œê°í™” ê²°ê³¼ ì €ì¥
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = f"./runs/run_{timestamp}"
    os.makedirs(save_dir, exist_ok=True)

    # 1) train.csv -> train, val split
    print("ğŸ“‚ train.csv ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    train_ds, val_ds = load_and_split_csv("./data", test_size=0.2, seed=42)

    # 2) í† í¬ë‚˜ì´ì¦ˆ: datasets.map() ì— desc ì¸ìë¥¼ ì£¼ë©´ tqdm ë°”ê°€ ìë™ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.
    print("ğŸ” train ë°ì´í„° í† í¬ë‚˜ì´ì¦ˆ ì¤‘...")
    train_ds = train_ds.map(
        tokenize_fn,
        batched=True,
        desc="Tokenizing train set"  # tqdm ë°” ì„¤ëª…
    )

    print("ğŸ” val ë°ì´í„° í† í¬ë‚˜ì´ì¦ˆ ì¤‘...")
    val_ds   = val_ds.map(
        tokenize_fn,
        batched=True,
        desc="Tokenizing val set"    # tqdm ë°” ì„¤ëª…
    )

    # 3) Trainer í˜¸í™˜ì„ ìœ„í•´ ì»¬ëŸ¼ëª… ë³€ê²½
    print("âœï¸ ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ ì¤‘ (label â†’ labels)...")
    train_ds = train_ds.rename_column("label", "labels")
    val_ds   = val_ds.rename_column("label", "labels")

    # 4) ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼(ì˜ˆ: pandas ì¸ë±ìŠ¤) ì œê±°
    #    Dataset.from_pandas() ì‹¤í–‰ ì‹œ "__index_level_0__" ì»¬ëŸ¼ì´ ë‚¨ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    if "__index_level_0__" in train_ds.column_names:
        train_ds = train_ds.remove_columns(["__index_level_0__"])
    if "__index_level_0__" in val_ds.column_names:
        val_ds   = val_ds.remove_columns(["__index_level_0__"])

    # 5) TrainingArguments & Trainer ì„¤ì •
    args = TrainingArguments(
        output_dir                   = save_dir,
        learning_rate                = 2e-5,
        per_device_train_batch_size  = 16,
        per_device_eval_batch_size   = 16,
        num_train_epochs             = 20,
        evaluation_strategy          = "epoch",
        save_strategy                = "epoch",
        load_best_model_at_end       = True,
        metric_for_best_model        = "f1",
        fp16                         = True,  # GPU í™˜ê²½ì´ ì•„ë‹ˆë©´ Falseë¡œ ë°”ê¿”ì£¼ì„¸ìš”
    )

    trainer = Trainer(
        model           = model,
        args            = args,
        train_dataset   = train_ds,
        eval_dataset    = val_ds,
        compute_metrics = compute_metrics,
        callbacks       = [EarlyStoppingCallback(early_stopping_patience=2)],
    )

    # 6) í•™ìŠµ ì‹œì‘
    print("ğŸš€ í•™ìŠµ ì‹œì‘...")
    trainer.train()

    # 7) í•™ìŠµ ì™„ë£Œ í›„, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    trainer.save_model(os.path.join(save_dir, "best_model"))
    print("âœ… í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥ë¨: ./causal_cls-best")

    # 8) í‰ê°€ì§€í‘œ ì €ì¥
    metrics = trainer.state.log_history
    metrics_dict = {}
    for entry in metrics:
        for key, value in entry.items():
            if key not in metrics_dict:
                metrics_dict[key] = []
            metrics_dict[key].append(value)
    plot_metrics(metrics_dict, save_dir)

    outputs = trainer.predict(val_ds)
    preds = np.argmax(outputs.predictions, axis=-1)
    probs = torch.nn.functional.softmax(torch.tensor(outputs.predictions), dim=-1)[:, 1].numpy()
    labels = outputs.label_ids

    plot_confusion(preds, labels, save_dir)
    plot_roc_auc(labels, probs, save_dir)
    print(f"âœ… ëª¨ë“  ê·¸ë˜í”„ì™€ ê²°ê³¼ê°€ {save_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()