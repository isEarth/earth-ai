"""
dataset.py

í…ìŠ¤íŠ¸ íŒŒì¼(.txt)ë“¤ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ê³ , ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì¸ê³¼ê´€ê³„ ì—¬ë¶€ë¥¼ ìë™ ë¼ë²¨ë§í•˜ì—¬
CSV í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
    python dataset.py --src raw_texts_dir/ --dst train
    python dataset.py --src /path/to/texts/ --dst output/train_data

ì…ë ¥:
    - src ë””ë ‰í† ë¦¬ ë‚´ë¶€ì˜ .txt íŒŒì¼ë“¤ (ê° íŒŒì¼ì€ 2ë²ˆì§¸ ì¤„ë¶€í„° ë³¸ë¬¸ ì‹œì‘)

ì¶œë ¥:
    - `--dst_YYYYMMDD_HHMMSS.csv` í˜•ì‹ì˜ CSV íŒŒì¼ ìƒì„±
    - ê° ë¬¸ì¥ì€ `sentence,label` í˜•ì‹ìœ¼ë¡œ ì €ì¥
"""

import re
import csv
from pathlib import Path
import datetime

from kiwipiepy import Kiwi
import kss                          # í•œê¸€ ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•´ kss ì‚¬ìš©
from tqdm import tqdm               # ì§„í–‰ ìƒí™© í‘œì‹œìš©
from patterns import CAUSAL_PATTERNS  # ì¸ê³¼ íŒ¨í„´(ì •ê·œì‹) ì •ì˜ íŒŒì¼

# -------------------------------------------------------------------
# 1) ì¸ê³¼ íŒ¨í„´ ì •ê·œì‹ì„ í•œ ë²ˆë§Œ ì»´íŒŒì¼í•´ ë‘¡ë‹ˆë‹¤.
compiled_patterns = [re.compile(p) for p in CAUSAL_PATTERNS]

kiwi = Kiwi()

def has_causal_phrase(sentence: str) -> bool:
    """
    ì£¼ì–´ì§„ ë¬¸ì¥ ë‚´ì— ì¸ê³¼ ê´€ê³„ íŒ¨í„´(ì •ê·œì‹)ì´ ì¡´ì¬í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

    Args:
        sentence (str): ê²€ì‚¬í•  ë¬¸ì¥ (í•œê¸€)

    Returns:
        bool: ì¸ê³¼ ê´€ê³„ íŒ¨í„´ì´ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ True, ì—†ìœ¼ë©´ False
    """
    tok = kiwi.tokenize(sentence, compatible_jamo=True)
    tok_sen = ' '.join([i.form for i in tok])
    return any(p.search(tok_sen) for p in compiled_patterns)

# -------------------------------------------------------------------
def build_csv(src_dir: str, dst_csv: str):
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .txt íŒŒì¼ì—ì„œ ë¬¸ì¥ì„ ì¶”ì¶œí•˜ê³ , ì¸ê³¼ ì—¬ë¶€ ë¼ë²¨ë§ í›„ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        src_dir (str): ì…ë ¥ .txt íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        dst_csv (str): ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ (í™•ì¥ìëŠ” ìë™ìœ¼ë¡œ `.csv`)

    ì²˜ë¦¬ ê³¼ì •:
        1. ëª¨ë“  .txt íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ê³  2ë²ˆì§¸ ì¤„ë¶€í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        2. ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ (KSS ì‚¬ìš©)
        3. ì¸ê³¼ê´€ê³„ ì •ê·œì‹ ë§¤ì¹­í•˜ì—¬ ë¼ë²¨ë§ (1: í¬í•¨, 0: ë¯¸í¬í•¨)
        4. sentence,label í˜•ì‹ìœ¼ë¡œ CSV ì €ì¥

    Returns:
        None: ê²°ê³¼ëŠ” íŒŒì¼ë¡œ ì €ì¥ë˜ë©° í•¨ìˆ˜ ìì²´ëŠ” ë°˜í™˜ê°’ì´ ì—†ìŠµë‹ˆë‹¤.
    """
    src_path = Path(src_dir)
    if not src_path.exists() or not src_path.is_dir():
        print(f"âš ï¸ ì˜¤ë¥˜: '{src_dir}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return

    # 2) ë””ë ‰í† ë¦¬ ë‚´ë¶€ì˜ ëª¨ë“  .txt íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜´ (í•˜ìœ„ ë””ë ‰í† ë¦¬ ë¯¸íƒìƒ‰)
    txt_files = list(src_path.glob("*.txt"))
    if len(txt_files) == 0:
        print(f"âš ï¸ '{src_dir}' ë””ë ‰í† ë¦¬ì— .txt íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3) ëª¨ë“  íŒŒì¼ ë‚´ìš©ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ë¡œ ë§Œë“¤ê¸°
    all_text = []
    print("ğŸ“‚ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ëŠ” ì¤‘...")
    for txt_file in tqdm(txt_files, desc="Reading .txt files", unit="file"):
        try:
            lines = txt_file.read_text(encoding="utf-8").splitlines()
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {txt_file} â†’ {e}")
            continue

        if len(lines) > 1:
            content = "\n".join(lines[1:]).strip()  # ë‘ ë²ˆì§¸ ì¤„ë¶€í„° ëê¹Œì§€ í•©ì¹¨
            all_text.append(content)
        else:
            print(f"âš ï¸ '{txt_file.name}' íŒŒì¼ì— ë‘ ë²ˆì§¸ ì¤„ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")

    # ì´ì œ all_textëŠ” ë””ë ‰í† ë¦¬ ë‚´ ê° í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë‚´ìš©ì„ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
    # ì´ë¥¼ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
    combined_text = "\n".join(all_text).strip()
    if not combined_text:
        print("âš ï¸ ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì½ì—ˆìœ¼ë‚˜, ë‚´ìš©ì´ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë‘ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
        return

    # 4) kssë¥¼ ì´ìš©í•´ í•œê¸€ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    print("ğŸ“ kss ë¬¸ì¥ ë¶„ë¦¬ ì¤‘...")
    try:
        sentences = kss.split_sentences(combined_text, backend='mecab')
    except Exception as e:
        print("âŒ kss ë¬¸ì¥ ë¶„ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return

    # 5) CSV íŒŒì¼ ì‘ì„± (í—¤ë”: sentence,label)
    print("ğŸ’¾ CSV ìƒì„± ì¤‘...")
    with open(dst_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["sentence", "label"])  # í—¤ë”

        count = 0
        # tqdmì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ í‘œì‹œ
        for sent in tqdm(sentences, desc="Processing sentences", unit="sent"):
            sent = sent.strip()
            if not sent:
                continue

            # ì¸ê³¼ íŒ¨í„´ ë§¤ì¹­ â†’ ì¸ê³¼ ë¬¸ì¥ì´ë©´ 1, ì•„ë‹ˆë©´ 0
            label = 1 if has_causal_phrase(sent) else 0
            writer.writerow([sent, label])
            count += 1

    print(f"âœ… '{dst_csv}' ìƒì„± ì™„ë£Œ - ì´ {count}ê°œ ë¬¸ì¥ ì²˜ë¦¬ë¨")

# -------------------------------------------------------------------
if __name__ == "__main__":
    """
    ëª…ë ¹ì¤„ ì¸ìë¥¼ í†µí•´ ë””ë ‰í† ë¦¬ ë‚´ .txt íŒŒì¼ì„ ì½ê³  CSV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    í•„ìˆ˜ ì¸ì:
        --src: ì…ë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        --dst: ê²°ê³¼ íŒŒì¼ ì´ë¦„ ì ‘ë‘ì–´ (í™•ì¥ìëŠ” ìë™ìœ¼ë¡œ ë¶™ìŒ)

    ì˜ˆì‹œ:
        python dataset.py --src raw_texts/ --dst train
    """
    import argparse

    parser = argparse.ArgumentParser(
        description="ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .txt íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ì¥ ë‹¨ìœ„ CSV ìƒì„±"
    )
    parser.add_argument(
        "--src",
        required=True,
        help="ì›ë³¸ .txt íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )
    parser.add_argument(
        "--dst",
        required=True,
        help="ìƒì„±í•  CSV íŒŒì¼ ê²½ë¡œ (sentence,label í˜•ì‹)"
    )
    args = parser.parse_args()

    # í˜„ì¬ ë‚ ì§œ ë° ì‹œê°„ ì¶”ê°€
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

    # ìµœì¢… CSV íŒŒì¼ëª… ë§Œë“¤ê¸°
    output_csv = f"{args.dst}_{timestamp}.csv"

    build_csv(args.src, output_csv)
