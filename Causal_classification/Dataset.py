# Dataset.py
# ì‚¬ìš© ì˜ˆì‹œ:
#   python Dataset.py --src raw_texts_dir/ --dst train.csv
#   python Dataset.py --src /home/eunhyea/EARTH/ConceptMap/topic/download_folder/ --dst train.csv

import re
import csv
from pathlib import Path
import datetime

from kiwipiepy import Kiwi
import kss                          # í•œê¸€ ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•´ kss ì‚¬ìš©
from tqdm import tqdm               # ì§„í–‰ ìƒí™© í‘œì‹œìš©
from patterns import CAUSAL_PATTERNS  # ì¸ê³¼ íŒ¨í„´(ì •ê·œì‹) ì •ì˜ íŒŒì¼

# -------------------------------------------------------------------
# 1) ì¸ê³¼ íŒ¨í„´ ì •ê·œì‹ì„ í•œ ë²ˆë§Œ ì»´íŒŒì¼í•´ ë‘¡ë‹ˆë‹¤.
compiled_patterns = [re.compile(p) for p in CAUSAL_PATTERNS]

kiwi = Kiwi()

def has_causal_phrase(sentence: str) -> bool:
    """
    ë¬¸ì¥ì— ì¸ê³¼ ê´€ê³„ íŒ¨í„´(ì •ê·œì‹)ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ True ë°˜í™˜
    """
    tok = kiwi.tokenize(sentence, compatible_jamo=True)
    tok_sen = ' '.join([i.form for i in tok])
    return any(p.search(tok_sen) for p in compiled_patterns)

# -------------------------------------------------------------------
def build_csv(src_dir: str, dst_csv: str):
    """
    src_dir: ì›ë³¸ .txt íŒŒì¼ë“¤ì´ ëª¨ì—¬ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
    dst_csv: 'sentence,label' í˜•ì‹ìœ¼ë¡œ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ

    ë™ì‘ ìˆœì„œ:
      1) src_dir ë‚´ë¶€ì˜ ëª¨ë“  .txt íŒŒì¼ì„ ì°¾ì•„ì„œ ë‚´ìš©ì„ ì½ì–´ë“¤ì„
      2) ê° íŒŒì¼ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ë¡œ í•©ì¹¨
      3) kss.split_sentences(...)ë¡œ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ â†’ ë¦¬ìŠ¤íŠ¸
      4) ê° ë¬¸ì¥ë§ˆë‹¤ has_causal_phrase(...)ë¡œ ë¼ë²¨(0/1) ê²°ì •
      5) ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ (í—¤ë”: sentence,label)
    """
    src_path = Path(src_dir)
    if not src_path.exists() or not src_path.is_dir():
        print(f"âš ï¸ ì˜¤ë¥˜: '{src_dir}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return

    # 2) ë””ë ‰í† ë¦¬ ë‚´ë¶€ì˜ ëª¨ë“  .txt íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜´ (í•˜ìœ„ ë””ë ‰í† ë¦¬ ë¯¸íƒìƒ‰)
    txt_files = list(src_path.glob("*.txt"))
    if len(txt_files) == 0:
        print(f"âš ï¸ '{src_dir}' ë””ë ‰í† ë¦¬ì— .txt íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3) ëª¨ë“  íŒŒì¼ ë‚´ìš©ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ë¡œ ë§Œë“¤ê¸°
    all_text = []
    print("ğŸ“‚ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ëŠ” ì¤‘...")
    for txt_file in tqdm(txt_files, desc="Reading .txt files", unit="file"):
        try:
            lines = txt_file.read_text(encoding="utf-8").splitlines()
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {txt_file} â†’ {e}")
            continue

        if len(lines) > 1:
            content = "\n".join(lines[1:]).strip()  # ë‘ ë²ˆì§¸ ì¤„ë¶€í„° ëê¹Œì§€ í•©ì¹¨
            all_text.append(content)
        else:
            print(f"âš ï¸ '{txt_file.name}' íŒŒì¼ì— ë‘ ë²ˆì§¸ ì¤„ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")

    # ì´ì œ all_textëŠ” ë””ë ‰í† ë¦¬ ë‚´ ê° í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë‚´ìš©ì„ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
    # ì´ë¥¼ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
    combined_text = "\n".join(all_text).strip()
    if not combined_text:
        print("âš ï¸ ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì½ì—ˆìœ¼ë‚˜, ë‚´ìš©ì´ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë‘ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
        return

    # 4) kssë¥¼ ì´ìš©í•´ í•œê¸€ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    print("ğŸ“ kss ë¬¸ì¥ ë¶„ë¦¬ ì¤‘...")
    try:
        sentences = kss.split_sentences(combined_text, backend='mecab')
    except Exception as e:
        print("âŒ kss ë¬¸ì¥ ë¶„ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return

    # 5) CSV íŒŒì¼ ì‘ì„± (í—¤ë”: sentence,label)
    print("ğŸ’¾ CSV ìƒì„± ì¤‘...")
    with open(dst_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["sentence", "label"])  # í—¤ë”

        count = 0
        # tqdmì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ í‘œì‹œ
        for sent in tqdm(sentences, desc="Processing sentences", unit="sent"):
            sent = sent.strip()
            if not sent:
                continue

            # ì¸ê³¼ íŒ¨í„´ ë§¤ì¹­ â†’ ì¸ê³¼ ë¬¸ì¥ì´ë©´ 1, ì•„ë‹ˆë©´ 0
            label = 1 if has_causal_phrase(sent) else 0
            writer.writerow([sent, label])
            count += 1

    print(f"âœ… '{dst_csv}' ìƒì„± ì™„ë£Œ - ì´ {count}ê°œ ë¬¸ì¥ ì²˜ë¦¬ë¨")

# -------------------------------------------------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .txt íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ì¥ ë‹¨ìœ„ CSV ìƒì„±"
    )
    parser.add_argument(
        "--src",
        required=True,
        help="ì›ë³¸ .txt íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )
    parser.add_argument(
        "--dst",
        required=True,
        help="ìƒì„±í•  CSV íŒŒì¼ ê²½ë¡œ (sentence,label í˜•ì‹)"
    )
    args = parser.parse_args()
    
    # í˜„ì¬ ë‚ ì§œ ë° ì‹œê°„ ì¶”ê°€
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ìµœì¢… CSV íŒŒì¼ëª… ë§Œë“¤ê¸°
    output_csv = f"{args.dst}_{timestamp}.csv"

    build_csv(args.src, output_csv)