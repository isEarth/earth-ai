# Clause-Level Semantic Similarity Pipeline

ì´ í”„ë¡œì íŠ¸ëŠ” ë¬¸ì¥ ë˜ëŠ” ì ˆ(clause) ë‹¨ìœ„ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ, ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ì˜ë¯¸ ìœ ì‚¬ì„±ì„ íš¨ìœ¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
PyTorch ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµê³¼ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë©°, ScaNN/Faiss ê¸°ë°˜ì˜ ë¹ ë¥¸ ê²€ìƒ‰ ë° ì •í™•í•œ cosine ë¹„êµê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤.

---

## ğŸ“Œ ì£¼ìš” êµ¬ì„± íŒŒì¼

### 1. `train.py` â€” ë¬¸ì¥ ë¶„ë¥˜ê¸° í•™ìŠµ
- ì‚¬ìš© ëª¨ë¸:  `KF-DeBERTa` + `TaggingModel`
- ëª©ì : ë¬¸ì¥ì„ ì ˆ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê¸° ìœ„í•œ ì‹œí€€ìŠ¤ íƒœê¹… ëª¨ë¸ í•™ìŠµ
- íŠ¹ì§•:
  - Custom token classifier : [ O, End, Inner end, Condition ] (weighted)
  - Custom loss (e.g., weighted CrossEntropy)
  - Accelerate / Trainer ì§€ì›
<p align="center">
  <img src="./image.png" height="150"/>   <img src="./image-1.png" height="150"/>
</p>
### 2. `prediction.py` â€” ì ˆ ë‹¨ìœ„   ê´€ê³„ ì¶”ì¶œ
- ì…ë ¥: ë¹„ì •ì œ youtubesript (raw text)
- ì¶œë ¥: ê° í† í°ì˜ O/E/I/C íƒœê·¸ ì˜ˆì¸¡ ë° ì ˆ êµ¬ë¬¸ ë¶„ë¦¬

####  ê¸°ëŠ¥ ìš”ì•½
- DeBERTa ê¸°ë°˜ í† í° ë¶„ë¥˜ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì ˆì˜ ê²½ê³„(E/E2/E3)ë¥¼ ì˜ˆì¸¡  
- `confidence_threshold`ì— ë”°ë¼ ë¶ˆí™•ì‹¤í•œ ê²½ê³„ ë³´ì • ê°€ëŠ¥ (ì ˆ ë¶„ë¦¬ ë¯¼ê°ë„ ì¡°ì ˆ)  
- batch ë‹¨ìœ„ë¡œ ë¬¸ì¥ì„ ì²˜ë¦¬í•˜ë©° `tqdm`ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì¶œë ¥  
- WordPiece ê¸°ë°˜ í† í¬ë‚˜ì´ì§• í›„ ì›ë¬¸ ë³µì› ë° ì ˆ ë‹¨ìœ„ êµ¬ì„±ê¹Œì§€ ìë™ ì²˜ë¦¬  
- ì ˆ ê°„ ì˜ë¯¸ì  ê´€ê³„ ì¶”ì¶œ(triplet êµ¬ì„±)ì„ ìœ„í•œ ë‹¨ì„œ ê¸°ë°˜ í›„ì²˜ë¦¬ ë¡œì§ í¬í•¨ ê°€ëŠ¥  

####  í™œìš© ëª©ì 
- `ClauseSpliting` íŒŒì´í”„ë¼ì¸ ë‚´ í•µì‹¬ ëª¨ë“ˆë¡œ ì‘ë™  
- Knowledge Graph êµ¬ì¶•ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ì ˆ ë° ê´€ê³„ ì •ë³´ì˜ ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹  
<p align="center">

![alt text](image-2.png)
</p>
<p align="center">
<img src="./image-3.png" width="500"/> 
</p>

### 3. `decide_same.py` â€” ì˜ë¯¸ ìœ ì‚¬ êµ¬ë¬¸ í›„ë³´ íƒìƒ‰
- ì…ë ¥: ì ˆ ë‹¨ìœ„ ì„ë² ë”© ë²¡í„° (SBERT, DeBERTa ê¸°ë°˜)
- ì²˜ë¦¬ íë¦„:
  1. `Linear(768â†’64)` íˆ¬ì‚¬ í›„ cosine ìœ ì‚¬ë„ ìƒìœ„ Nê°œ fast filtering
  2. ì •ë°€ ë¹„êµ ìœ„í•´ ì›ë˜ 768 ì„ë² ë”© ê¸°ë°˜ cosine ìœ ì‚¬ë„ ì¬ê³„ì‚°
  3. threshold ê¸°ë°˜ filtering and euclidian distanceë„ ê³ ë ¤í•˜ì—¬ ê´€ê³„ë¶„ë¥˜
- íŠ¹ì§•:
  - `torch.matmul`ì„ batchë¡œ ë‚˜ëˆ  ë©”ëª¨ë¦¬ ìµœì í™”
  - Fast filteringì€ ìƒì‚¼ê°ë§Œ ê³„ì‚°í•˜ì—¬ ì¤‘ë³µ ì œê±°

### 4. `test.py` â€” ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
- êµ¬ì„±:
  - ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
  - prediction â†’ embedding â†’ similarity â†’ filtering ê¹Œì§€ ì—°ê²°
- ê²°ê³¼:
  - ì˜ë¯¸ ìœ ì‚¬í•œ ì ˆìŒ ì¶œë ¥
  - ìµœì¢… ê²°ê³¼ëŠ” `(id1, id2, similarity)` í˜•íƒœë¡œ `.npy` ì €ì¥

---

## âš™ï¸ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ

| Task               | Tool/Library                |
|--------------------|-----------------------------|
| Transformer ëª¨ë¸   | HuggingFace Transformers    |
| ì„ë² ë”©            | KoBERT / KF-DeBERTa         |
| í† í°í™”            | `AutoTokenizer`, `Kiwi`     |
| ìœ ì‚¬ë„ ê³„ì‚°       | PyTorch `cosine_similarity` |
| ë¹ ë¥¸ íƒìƒ‰         | FAISS / ScaNN (ì„ íƒ ê°€ëŠ¥)  |
| ì‹œê°í™”/ì§„í–‰ìƒí™©    | `tqdm`, `matplotlib`         |

---

## ğŸ’¾ ë°ì´í„° ì €ì¥ ë°©ì‹

- ì ˆ ë²¡í„°: `embedding_batch_*.npy`
- ìœ ì‚¬ ì ˆìŒ: `similar_temp.npy` (ìµœì¢… ê²°ê³¼)
- prediction ê²°ê³¼: `.jsonl` or `.json`

---

## ğŸ“ˆ í–¥í›„ ê°œì„ ì 

- GPU ë¶„ì‚° inference
- ì˜ë¯¸ ê°•ì¡° ë‹¨ì–´ ìë™ í•˜ì´ë¼ì´íŠ¸
- ë¬¸ì¥ ê°„ ë…¼ë¦¬ì  ê´€ê³„ ì¶”ì¶œ (ì¸ê³¼ / ëŒ€ì¡° ë“±)
- MILVUS ì—°ë™ or RAG ì—”ì§„ êµ¬ì„±

---

## ğŸ“‚ ì˜ˆì‹œ ì‹¤í–‰ íë¦„

```bash
# 1. ëª¨ë¸ í•™ìŠµ
python train.py --config configs/kf_deberta.yaml

# 2. ì ˆ ë¶„í•  ì˜ˆì¸¡
python prediction.py --input input_text.txt --output predicted_clauses.jsonl

# 3. ìœ ì‚¬ ì ˆìŒ íƒìƒ‰
python decide_same.py --input predicted_clauses.jsonl --output similar_temp.npy

# 4. ê²°ê³¼ ê²€ì¦
python test.py --input similar_temp.npy
```
---
## ğŸ§‘â€ğŸ’» ì‚¬ìš© ì•ˆë‚´ (Usage Guide)

### ğŸ”¹ 1. `train.py` â€” ì ˆ êµ¬ë¶„ ëª¨ë¸ í•™ìŠµ

```bash
python train.py --config configs/kf_deberta.yaml
```

- **ì…ë ¥**: YAML ì„¤ì • íŒŒì¼ (`configs/*.yaml`)  
- **ì¶œë ¥**: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸, ë¡œê·¸ íŒŒì¼, ì„±ëŠ¥ ì‹œê°í™”  
- **ê¸°ëŠ¥**: KF-DeBERTa ë˜ëŠ” KoBERT ê¸°ë°˜ ì ˆ êµ¬ë¶„ BIO / E / E2 / E3 íƒœê·¸ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ

---

### ğŸ”¹ 2. `prediction.py` â€” ë¬¸ì¥ì„ ì ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬

```bash
python prediction.py --input input_text.txt --output predicted_clauses.jsonl
```

- **ì…ë ¥ ì˜ˆì‹œ (`input_text.txt`)**:

  ```
  ê²½ì œì„±ì¥ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ê¸ˆë¦¬ë¥¼ ì¸í•˜í–ˆë‹¤.
  ì¸í”Œë ˆì´ì…˜ì´ ìš°ë ¤ë˜ì ë‹¤ì‹œ ê¸ˆë¦¬ë¥¼ ì¸ìƒí–ˆë‹¤.
  ```

- **ì¶œë ¥ ì˜ˆì‹œ (`predicted_clauses.jsonl`)**:

  ```json
  {"clause": ["ê²½ì œì„±ì¥ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´", "ê¸ˆë¦¬ë¥¼ ì¸í•˜í–ˆë‹¤"]}
  {"clause": ["ì¸í”Œë ˆì´ì…˜ì´ ìš°ë ¤ë˜ì", "ë‹¤ì‹œ ê¸ˆë¦¬ë¥¼ ì¸ìƒí–ˆë‹¤"]}
  ```

- **ê¸°ëŠ¥**: ë¬¸ì¥ì„ í˜•íƒœì†Œ ê¸°ë°˜ í† í¬ë‚˜ì´ì§• â†’ íƒœê¹… ëª¨ë¸ â†’ ì ˆ ë‹¨ìœ„ ë¶„ë¦¬

---

### ğŸ”¹ 3. `decide_same.py` â€” ìœ ì‚¬ ì ˆìŒ íƒìƒ‰ ë° ì •ë°€ ìœ ì‚¬ë„ ê³„ì‚°

```bash
python decide_same.py --input predicted_clauses.jsonl --output similar_temp.npy
```

- **ì²˜ë¦¬ ê³¼ì •**:
  - `Linear(768â†’256â†’64)` íˆ¬ì˜ â†’ cosine ê¸°ë°˜ Top-K í›„ë³´ íƒìƒ‰
  - ì›ë³¸ `768` ì°¨ì›ìœ¼ë¡œ ë‹¤ì‹œ ì •í™•í•œ ìœ ì‚¬ë„ ê³„ì‚°

- **ì¶œë ¥** (`similar_temp.npy`):

  ```python
  [
    (clause_id1, clause_id2, similarity_score),
    ...
  ]
  ```

- **ê¸°ëŠ¥**: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì ˆ ìŒ ì¶”ì¶œ

---

### ğŸ”¹ 4. `test.py` â€” ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

```bash
python test.py --input input_text.txt
```

- **ê¸°ëŠ¥**:
  - ë¬¸ì¥ ì…ë ¥ â†’ ì ˆ ë¶„ë¦¬ â†’ ìœ ì‚¬ ì ˆ í›„ë³´ ë„ì¶œ â†’ cosine ìœ ì‚¬ë„ ê³„ì‚°
  - ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì— í™•ì¸ ê°€ëŠ¥

---

## ğŸ“¦ ìš”êµ¬ì‚¬í•­ (Requirements)

```bash
pip install -r requirements.txt
```

- PyTorch
- transformers
- tqdm
- numpy
- scikit-learn
- kiwipiepy
- accelerate (ì„ íƒ)

---

## ğŸ“Œ ì°¸ê³ 

- ì ˆ ë‹¨ìœ„ ë¶„ë¦¬ íƒœê·¸: `O`, `E`, `E2`, `E3`
- `768 â†’ 64` ì°¨ì› ì¶•ì†ŒëŠ” `nn.Linear` ê¸°ë°˜
- similarity threshold ë˜ëŠ” Top-K ê¸°ë°˜ìœ¼ë¡œ í›„ë³´ í•„í„°ë§

---